{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 官方教程\n",
    "\n",
    "从官方教程出发，总是能获得精确核心的描述。\n",
    "\n",
    "- Generalizing well-established neural models like RNNs or CNNs to work on arbitrarily structured graphs is a challenging problem. \n",
    "- Cora 数据集合中如果不用图网络，就做一个简单的分类模型，准确率能达到多少？\n",
    "- 在这里我们的样本是图，每个样本是一个结点，而特征不是图。\n",
    "- 从 Cora 例子可以看出，图网络是从IID到Non-IID的过渡，样本之间的相关性.\n",
    "- Graph Pooling 会改变图结构吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "![](http://tkipf.github.io/graph-convolutional-networks/images/gcn_web.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Research Ideas\n",
    "\n",
    "- T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction, 时间序列的每个样本可以当成一个节点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Quick Start\n",
    "\n",
    "快速的看看有哪些官方教程和相关文档分别讲了什么。发现要理解这个官方教程，需要做如下的事情：\n",
    "\n",
    "-  找到对应的文档说明 \n",
    "    - What is edge convolutional layer?\n",
    "    - What is MessagePassing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- https://github.com/rusty1s/pytorch_geometric\n",
    "\n",
    "PyTorch Geometric (PyG) is a geometric deep learning extension library for PyTorch.\n",
    "\n",
    "It consists of various methods for deep learning on graphs and other irregular structures, also known as geometric deep learning, from a variety of published papers. In addition, it consists of an easy-to-use mini-batch loader for many small and single giant graphs, multi gpu-support, a large number of common benchmark datasets (based on simple interfaces to create your own), and helpful transforms, both for learning on arbitrary graphs as well as on 3D meshes or point clouds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- https://pytorch-geometric.readthedocs.io/en/latest/index.html\n",
    "\n",
    "PyTorch Geometric user document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Zero To All\n",
    "\n",
    "详细看看官方教程的关注内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "## PyTorch Geometric Docs\n",
    "\n",
    "site: https://pytorch-geometric.readthedocs.io/en/latest/index.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Introduction by Example\n",
    "\n",
    "We shortly introduce the fundamental concepts of PyTorch Geometric through self-contained examples. At its core, PyTorch Geometric provides the following main features:\n",
    "\n",
    "- Data Handling of Graphs\n",
    "- Common Benchmark Datasets\n",
    "- Mini-batches\n",
    "- Data Transforms 是什么？Transforms are a common way in torchvision to transform images and perform augmentation. 是数据增强的一种方式。\n",
    "- Learning Methods on Graphs 有什么？For a high-level explanation on GCN, have a look at its [blog post](http://tkipf.github.io/graph-convolutional-networks/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "首先需要介绍的是数据类型，居然有一些不错的方法：\n",
    "\n",
    "- data.contains_isolated_nodes() 会计算每个节点的度？\n",
    "- data.contains_self_loops() 会有 loops ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "#数据集加载\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='./tmp/Cora', name='Cora')\n",
    "device = torch.device('cpu')\n",
    "data = dataset[0].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape # 2708 篇文献， 1403个关键词 === [num_nodes, num_node_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10556])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape # [2, num_edges] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, torch.Size([2708]), None, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_attr, data.y.shape, data.pos, data.face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We show a simple example of an unweighted and undirected graph with three nodes and four edges. Each node contains exactly one feature: \n",
    "\n",
    "![](https://pytorch-geometric.readthedocs.io/en/latest/_images/graph.svg)\n",
    "\n",
    "该例子和普通概率图例子稍微有点不一样，有几个注意点：\n",
    "\n",
    "- $x_1=-1$ 是第一个节点的一个特征\n",
    "- 两条边需要用 four index tuples 来表示. Although the graph has only two edges, we need to define four index tuples to account for both directions of a edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4], x=[3, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "PyTorch Geometric contains a large number of common benchmark datasets, e.g. all Planetoid datasets (Cora, Citeseer, Pubmed), all graph classification datasets from http://graphkernels.cs.tu-dortmund.de/ and their cleaned versions, the QM7 and QM9 dataset, and a handful of 3D mesh/point cloud datasets like FAUST, ModelNet10/40 and ShapeNet.\n",
    "\n",
    "Initializing a dataset is straightforward. An initialization of a dataset will automatically download its raw files and process them to the previously described Data format. E.g., to load the ENZYMES dataset (consisting of 600 graphs within 6 classes), type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ls11-www.cs.tu-dortmund.de/people/morris/graphkerneldatasets/ENZYMES.zip\n",
      "Extracting tmp/ENZYMES/ENZYMES.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "dataset = TUDataset(root='./tmp/ENZYMES', name='ENZYMES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1433, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes, dataset.num_node_features, len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(edge_index=[2, 168], x=[37, 3], y=[1]), True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data, data.is_undirected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Creating Message Passing Networks\n",
    "\n",
    "- 为什么是图卷积的推广？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- 官方理解 [Creating Message Passing Networks](https://github.com/rusty1s/pytorch_geometric/blob/master/docs/source/notes/create_gnn.rst)\n",
    "\n",
    "\n",
    "Generalizing the convolution operator to irregular domains is typically expressed as a *neighborhood aggregation* or *message passing* scheme. With $\\mathbf{x}^{(k-1)}_i \\in \\mathbb{R}^F$ denoting node features of node $i$ in layer $(k-1)$ and $\\mathbf{e}_{i,j} \\in \\mathbb{R}^D$ denoting (optional) edge features from node $i$ to node $j$, message passing graph neural networks can be described as\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{i,j}\\right) \\right),\n",
    "$$\n",
    "\n",
    "where $\\square$ denotes a differentiable, permutation invariant function, e.g., sum, mean or max, and $\\gamma$ and $\\phi$ denote differentiable functions such as MLPs (Multi Layer Perceptrons)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "和图卷积的关系\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{deg(j)}} \\cdot \\left( \\mathbf{\\Theta} \\cdot \\mathbf{x}_j^{(k-1)} \\right),\n",
    "$$\n",
    "\n",
    "where neighboring node features are first transformed by a weight matrix $\\Theta$, normalized by their degree, and finally summed up. $\\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{deg(j)}}$ 表示 Adjacent.\n",
    "\n",
    "代码中的写法是这样的：The graph convolutional operator from the “Semi-supervised Classification with Graph Convolutional Networks” paper\n",
    "\n",
    "$$\n",
    "\\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
    "\\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta},\n",
    "$$\n",
    "\n",
    "where $\\hat{A}=A+I$ denotes the adjacency matrix with inserted self-loops and $D^{ii}=\\sum_{j=0}A_{ij}$ its diagonal degree matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- 那么为什么是 GAT 的推广呢？\n",
    "    - 边信息： $e_{ij}^k = a^k(Wh_i, W h_j)$\n",
    "    - 结点更新：$h'_i = \\sigma(\\frac{1}{K}\\sum_{k=1}^K\\sum_{j\\in N_i} \\alpha_{ij}^kW^k h_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 注意力机制网络\n",
    "\n",
    "\n",
    "site: https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The graph attentional operator from the “Graph Attention Networks” paper\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^{\\prime}_i = \\alpha_{i,i}\\mathbf{\\Theta}\\mathbf{x}_{i} +\n",
    "\\sum_{j \\in \\mathcal{N}(i)} \\alpha_{i,j}\\mathbf{\\Theta}\\mathbf{x}_{j},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "where the attention coefficients $\\alpha_{i,j}$ are computed as\n",
    "\n",
    "$$\n",
    "\\alpha_{i,j} =\n",
    "\\frac{\n",
    "\\exp\\left(\\mathrm{LeakyReLU}\\left(\\mathbf{a}^{\\top}\n",
    "[\\mathbf{\\Theta}\\mathbf{x}_i \\, \\Vert \\, \\mathbf{\\Theta}\\mathbf{x}_j]\n",
    "\\right)\\right)}\n",
    "{\\sum_{k \\in \\mathcal{N}(i) \\cup \\{ i \\}}\n",
    "\\exp\\left(\\mathrm{LeakyReLU}\\left(\\mathbf{a}^{\\top}\n",
    "[\\mathbf{\\Theta}\\mathbf{x}_i \\, \\Vert \\, \\mathbf{\\Theta}\\mathbf{x}_k]\n",
    "\\right)\\right)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "这个网络继承自一个很好父类, **有关于继承的trick可以学习**。 MessagePassing site: https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Pooling \n",
    "\n",
    "有多种不同的 pooling\n",
    "\n",
    "- global_add_pool(x, batch, size=None)\n",
    "- global_mean_pool(x, batch, size=None)\n",
    "- global_max_pool(x, batch, size=None)\n",
    "\n",
    "那么 Pooling 会改变图结构吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## 官方推荐博客\n",
    "\n",
    "site: http://tkipf.github.io/graph-convolutional-networks/\n",
    "\n",
    "需要从这个博客中了解到GCN的每个实现细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "![](http://tkipf.github.io/graph-convolutional-networks/images/gcn_web.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 两层 GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7940\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "#数据集加载\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='./tmp/Cora', name='Cora')\n",
    "len(dataset), dataset.num_classes, dataset.num_node_features\n",
    "\n",
    "#网络定义\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "#网络训练\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "#测试\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 1433])\n",
      "torch.Size([2708, 16])\n",
      "torch.Size([2708, 7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "#数据集加载\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='./tmp/Cora', name='Cora')\n",
    "len(dataset), dataset.num_classes, dataset.num_node_features\n",
    "\n",
    "#网络定义\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        self.fc = nn.Linear(7, 7) # 加入全连接层\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index \n",
    "        print(x.shape)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        print(x.shape)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.fc(x) \n",
    "        print(x.shape)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "out = model(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2708, 1433]), torch.Size([2, 10556]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape, data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1433, 16]),\n",
       " torch.Size([16]),\n",
       " torch.Size([16, 7]),\n",
       " torch.Size([7])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index # Adjacent Matrix 的维度应该是 [N, N] , 也就是 [2708, 2708]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "相邻的边才能影响到相关的取值 with $A$ is the Adjacent Matrix. 在网络中这应该是一个自动去计算的模块。\n",
    "\n",
    "$$\n",
    "\\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta},  \n",
    "$$\n",
    "\n",
    "为什么这个数学公式做到了只有相邻节点的边会影响状态更新呢？从简单出发，如没有没有 $A$（也就是说 $A=I$），那么就样本之间相互不会影响，有了 $A$ 就相当于考虑的非独立同分布的数据，样本之间有了相互影响。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mimproved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "The graph convolutional operator from the `\"Semi-supervised\n",
       "Classification with Graph Convolutional Networks\"\n",
       "<https://arxiv.org/abs/1609.02907>`_ paper\n",
       "\n",
       ".. math::\n",
       "    \\mathbf{X}^{\\prime} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
       "    \\mathbf{\\hat{D}}^{-1/2} \\mathbf{X} \\mathbf{\\Theta},\n",
       "\n",
       "where :math:`\\mathbf{\\hat{A}} = \\mathbf{A} + \\mathbf{I}` denotes the\n",
       "adjacency matrix with inserted self-loops and\n",
       ":math:`\\hat{D}_{ii} = \\sum_{j=0} \\hat{A}_{ij}` its diagonal degree matrix.\n",
       "\n",
       "Args:\n",
       "    in_channels (int): Size of each input sample.\n",
       "    out_channels (int): Size of each output sample.\n",
       "    improved (bool, optional): If set to :obj:`True`, the layer computes\n",
       "        :math:`\\mathbf{\\hat{A}}` as :math:`\\mathbf{A} + 2\\mathbf{I}`.\n",
       "        (default: :obj:`False`)\n",
       "    cached (bool, optional): If set to :obj:`True`, the layer will cache\n",
       "        the computation of :math:`\\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
       "        \\mathbf{\\hat{D}}^{-1/2}` on first execution, and will use the\n",
       "        cached version for further executions.\n",
       "        This parameter should only be set to :obj:`True` in transductive\n",
       "        learning scenarios. (default: :obj:`False`)\n",
       "    bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
       "        an additive bias. (default: :obj:`True`)\n",
       "    **kwargs (optional): Additional arguments of\n",
       "        :class:`torch_geometric.nn.conv.MessagePassing`.\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/torch_geometric/nn/conv/gcn_conv.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?GCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Research on this topic is just getting started. The past several months have seen exciting developments, but we have probably only scratched the surface of these types of models so far. It remains to be seen how neural networks on graphs can be further taylored to specific types of problems, like, e.g., learning on directed or relational graphs, and how one can use learned graph embeddings for further tasks down the line, etc. This list is by no means exhaustive and I expect further interesting applications and extensions to pop up in the near future. Let me know in the comments below if you have some exciting ideas or questions to share!\n",
    "\n",
    "\n",
    "关于该主题的研究才刚刚开始。在过去的几个月中，出现了令人振奋的发展，但到目前为止，我们可能只涉及这些类型的模型。还有待观察的是，图上的神经网络如何进一步解决特定类型的问题，例如在有向图或关系图上学习，以及如何将学习到的图嵌入用于线下的其他任务等。此列表这绝不是详尽无遗的，我希望在不久的将来会出现更多有趣的应用程序和扩展。如果您有一些令人兴奋的想法或问题要分享，请在下面的评论中告诉我！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

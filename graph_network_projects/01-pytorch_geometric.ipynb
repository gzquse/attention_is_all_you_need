{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Graph Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
      "Collecting torch-scatter==latest+cu102\n",
      "  Downloading https://pytorch-geometric.com/whl/torch-1.6.0/torch_scatter-latest%2Bcu102-cp37-cp37m-linux_x86_64.whl (11.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.6 MB 135 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: torch-scatter\n",
      "  Attempting uninstall: torch-scatter\n",
      "    Found existing installation: torch-scatter 2.0.5\n",
      "    Uninstalling torch-scatter-2.0.5:\n",
      "      Successfully uninstalled torch-scatter-2.0.5\n",
      "Successfully installed torch-scatter-2.0.5\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
      "Collecting torch-sparse==latest+cu102\n",
      "  Downloading https://pytorch-geometric.com/whl/torch-1.6.0/torch_sparse-latest%2Bcu102-cp37-cp37m-linux_x86_64.whl (23.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.0 MB 101 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-sparse==latest+cu102) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from scipy->torch-sparse==latest+cu102) (1.18.1)\n",
      "Installing collected packages: torch-sparse\n",
      "  Attempting uninstall: torch-sparse\n",
      "    Found existing installation: torch-sparse 0.6.7\n",
      "    Uninstalling torch-sparse-0.6.7:\n",
      "      Successfully uninstalled torch-sparse-0.6.7\n",
      "Successfully installed torch-sparse-0.6.7\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
      "Collecting torch-cluster==latest+cu102\n",
      "  Downloading https://pytorch-geometric.com/whl/torch-1.6.0/torch_cluster-latest%2Bcu102-cp37-cp37m-linux_x86_64.whl (20.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.3 MB 152 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: torch-cluster\n",
      "  Attempting uninstall: torch-cluster\n",
      "    Found existing installation: torch-cluster 1.5.7\n",
      "    Uninstalling torch-cluster-1.5.7:\n",
      "      Successfully uninstalled torch-cluster-1.5.7\n",
      "Successfully installed torch-cluster-1.5.7\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
      "Collecting torch-spline-conv==latest+cu102\n",
      "  Downloading https://pytorch-geometric.com/whl/torch-1.6.0/torch_spline_conv-latest%2Bcu102-cp37-cp37m-linux_x86_64.whl (6.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.1 MB 170 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
      "  Attempting uninstall: torch-spline-conv\n",
      "    Found existing installation: torch-spline-conv 1.2.0\n",
      "    Uninstalling torch-spline-conv-1.2.0:\n",
      "      Successfully uninstalled torch-spline-conv-1.2.0\n",
      "Successfully installed torch-spline-conv-1.2.0\n",
      "Requirement already satisfied: torch-geometric in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (1.6.1)\n",
      "Requirement already satisfied: googledrivedownloader in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (0.4)\n",
      "Requirement already satisfied: networkx in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (2.4)\n",
      "Requirement already satisfied: tqdm in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (4.48.0)\n",
      "Requirement already satisfied: torch in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (1.6.0)\n",
      "Requirement already satisfied: ase in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (3.20.0)\n",
      "Requirement already satisfied: jinja2 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (2.11.1)\n",
      "Requirement already satisfied: numba in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (0.50.1)\n",
      "Requirement already satisfied: pandas in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (1.0.3)\n",
      "Requirement already satisfied: h5py in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (2.10.0)\n",
      "Requirement already satisfied: numpy in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (1.18.1)\n",
      "Requirement already satisfied: scipy in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: requests in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (2.23.0)\n",
      "Requirement already satisfied: rdflib in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (5.0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch-geometric) (0.22.2.post1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from networkx->torch-geometric) (4.4.2)\n",
      "Requirement already satisfied: future in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from torch->torch-geometric) (0.18.2)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from ase->torch-geometric) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from jinja2->torch-geometric) (1.1.1)\n",
      "Requirement already satisfied: llvmlite<0.34,>=0.33.0.dev0 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from numba->torch-geometric) (0.33.0)\n",
      "Requirement already satisfied: setuptools in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from numba->torch-geometric) (46.1.3.post20200330)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from pandas->torch-geometric) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from pandas->torch-geometric) (2019.3)\n",
      "Requirement already satisfied: six in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from h5py->torch-geometric) (1.14.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from requests->torch-geometric) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from requests->torch-geometric) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from requests->torch-geometric) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from requests->torch-geometric) (1.25.8)\n",
      "Requirement already satisfied: pyparsing in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from rdflib->torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: isodate in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from rdflib->torch-geometric) (0.6.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from scikit-learn->torch-geometric) (0.14.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tie/anaconda3/envs/torch/lib/python3.7/site-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
    "!pip install torch-sparse==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
    "!pip install torch-cluster==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
    "!pip install torch-spline-conv==latest+cu102 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Brainstorming\n",
    "\n",
    "图神经网络与图卷积网络 https://zhuanlan.zhihu.com/p/70028587 图监督学习的统一分析框架是：\n",
    "\n",
    "Aggregator:\n",
    "$$\n",
    "m_v^{t+1} = \\sum_{w \\in N_v} M_t(h_v^t, h_w^t, e_{vw})\n",
    "$$\n",
    "\n",
    "Updater:\n",
    "$$\n",
    "h_v^{t+1} = U_t(h_v^t, m_v^{t+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#  Quick Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## GCN 网络论文分类数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 从 Cora 出发 with GCN\n",
    "\n",
    "Cora：一个根据科学论文之间相互引用关系而构建的Graph数据集合，论文分为7类：Genetic_Algorithms，Neural_Networks，Probabilistic_Methods，Reinforcement_Learning，Rule_Learning，Theory，共2708篇；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-93fcb9a77972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_debug_enabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch_geometric/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetaLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch_geometric/nn/data_parallel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch_geometric/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0min_memory_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataListLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDenseDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoalesce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m from torch_geometric.utils import (contains_isolated_nodes,\n\u001b[1;32m      9\u001b[0m                                    contains_self_loops, is_undirected)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_sparse'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_sparse\n",
      "  Using cached https://files.pythonhosted.org/packages/db/d1/968436c29959c321740ee95f781c961f12b2d23f0ecdbdaaf3ccf64ddc94/torch_sparse-0.6.6.tar.gz\n",
      "Requirement already satisfied: scipy in /home/yons/anaconda3/envs/torch/lib/python3.6/site-packages (from torch_sparse) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/yons/.local/lib/python3.6/site-packages (from scipy->torch_sparse) (1.17.2)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/yons/anaconda3/envs/torch/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_leqep1z/torch-sparse/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_leqep1z/torch-sparse/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-96z0urld --python-tag cp36\n",
      "       cwd: /tmp/pip-install-_leqep1z/torch-sparse/\n",
      "  Complete output (83 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.6\n",
      "  creating build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/narrow.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/matmul.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/diag.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/bandwidth.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/cat.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/padding.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/index_select.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/spmm.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/add.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/masked_select.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/convert.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/eye.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/rw.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/select.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/tensor.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/sample.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/utils.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/permute.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/saint.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/storage.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/mul.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/metis.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/__init__.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/reduce.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  copying torch_sparse/transpose.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "  running build_ext\n",
      "  building 'torch_sparse._metis' extension\n",
      "  creating build/temp.linux-x86_64-3.6\n",
      "  creating build/temp.linux-x86_64-3.6/tmp\n",
      "  creating build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z\n",
      "  creating build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse\n",
      "  creating build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc\n",
      "  creating build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu\n",
      "  gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/tmp/pip-install-_leqep1z/torch-sparse/csrc -I/home/yons/.local/lib/python3.6/site-packages/torch/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/TH -I/home/yons/.local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/yons/anaconda3/envs/torch/include/python3.6m -c /tmp/pip-install-_leqep1z/torch-sparse/csrc/metis.cpp -o build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/metis.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_metis -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "  cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "  gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/tmp/pip-install-_leqep1z/torch-sparse/csrc -I/home/yons/.local/lib/python3.6/site-packages/torch/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/TH -I/home/yons/.local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/yons/anaconda3/envs/torch/include/python3.6m -c /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/metis_cpu.cpp -o build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/metis_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_metis -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "  cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "  g++ -pthread -shared -L/home/yons/anaconda3/envs/torch/lib -Wl,-rpath=/home/yons/anaconda3/envs/torch/lib,--no-as-needed build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/metis.o build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/metis_cpu.o -L/usr/local/cuda/lib64 -L/home/yons/anaconda3/envs/torch/lib -lcudart -lcudart -lcudart -lcudart -lcudart -lcudart -lcudart -lcudart -lcudart -lpython3.6m -o build/lib.linux-x86_64-3.6/torch_sparse/_metis.so -lcusparse -l cusparse\n",
      "  building 'torch_sparse._sample' extension\n",
      "  gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/tmp/pip-install-_leqep1z/torch-sparse/csrc -I/home/yons/.local/lib/python3.6/site-packages/torch/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/TH -I/home/yons/.local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/yons/anaconda3/envs/torch/include/python3.6m -c /tmp/pip-install-_leqep1z/torch-sparse/csrc/sample.cpp -o build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/sample.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_sample -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "  cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "  gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/tmp/pip-install-_leqep1z/torch-sparse/csrc -I/home/yons/.local/lib/python3.6/site-packages/torch/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/TH -I/home/yons/.local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/yons/anaconda3/envs/torch/include/python3.6m -c /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp -o build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_sample -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "  cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp: In function ‘std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> sample_adj_cpu(at::Tensor, at::Tensor, at::Tensor, at::Tensor, int64_t, bool)’:\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:14:45: error: expected primary-expression before ‘>’ token\n",
      "     auto rowptr_data = rowptr.data_ptr<int64_t>();\n",
      "                                               ^\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:14:47: error: expected primary-expression before ‘)’ token\n",
      "     auto rowptr_data = rowptr.data_ptr<int64_t>();\n",
      "                                                 ^\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:15:39: error: expected primary-expression before ‘>’ token\n",
      "     auto col_data = col.data_ptr<int64_t>();\n",
      "                                         ^\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:15:41: error: expected primary-expression before ‘)’ token\n",
      "     auto col_data = col.data_ptr<int64_t>();\n",
      "                                           ^\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:16:49: error: expected primary-expression before ‘>’ token\n",
      "     auto rowcount_data = rowcount.data_ptr<int64_t>();\n",
      "                                                   ^\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:16:51: error: expected primary-expression before ‘)’ token\n",
      "     auto rowcount_data = rowcount.data_ptr<int64_t>();\n",
      "                                                     ^\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:17:39: error: expected primary-expression before ‘>’ token\n",
      "     auto idx_data = idx.data_ptr<int64_t>();\n",
      "                                         ^\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:17:41: error: expected primary-expression before ‘)’ token\n",
      "     auto idx_data = idx.data_ptr<int64_t>();\n",
      "                                           ^\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:20:53: error: expected primary-expression before ‘>’ token\n",
      "     auto out_rowptr_data = out_rowptr.data_ptr<int64_t>();\n",
      "                                                       ^\n",
      "  /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:20:55: error: expected primary-expression before ‘)’ token\n",
      "     auto out_rowptr_data = out_rowptr.data_ptr<int64_t>();\n",
      "                                                         ^\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-sparse\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for torch-sparse\n",
      "Failed to build torch-sparse\n",
      "Installing collected packages: torch-sparse\n",
      "    Running setup.py install for torch-sparse ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/yons/anaconda3/envs/torch/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_leqep1z/torch-sparse/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_leqep1z/torch-sparse/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-3p6ks07m/install-record.txt --single-version-externally-managed --compile\n",
      "         cwd: /tmp/pip-install-_leqep1z/torch-sparse/\n",
      "    Complete output (83 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/narrow.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/matmul.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/diag.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/bandwidth.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/cat.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/padding.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/index_select.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/spmm.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/add.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/masked_select.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/convert.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/eye.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/rw.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/select.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/tensor.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/sample.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/utils.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/permute.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/saint.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/storage.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/mul.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/metis.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/__init__.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/reduce.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    copying torch_sparse/transpose.py -> build/lib.linux-x86_64-3.6/torch_sparse\n",
      "    running build_ext\n",
      "    building 'torch_sparse._metis' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/tmp\n",
      "    creating build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z\n",
      "    creating build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse\n",
      "    creating build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc\n",
      "    creating build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu\n",
      "    gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/tmp/pip-install-_leqep1z/torch-sparse/csrc -I/home/yons/.local/lib/python3.6/site-packages/torch/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/TH -I/home/yons/.local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/yons/anaconda3/envs/torch/include/python3.6m -c /tmp/pip-install-_leqep1z/torch-sparse/csrc/metis.cpp -o build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/metis.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_metis -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "    gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/tmp/pip-install-_leqep1z/torch-sparse/csrc -I/home/yons/.local/lib/python3.6/site-packages/torch/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/TH -I/home/yons/.local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/yons/anaconda3/envs/torch/include/python3.6m -c /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/metis_cpu.cpp -o build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/metis_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_metis -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "    g++ -pthread -shared -L/home/yons/anaconda3/envs/torch/lib -Wl,-rpath=/home/yons/anaconda3/envs/torch/lib,--no-as-needed build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/metis.o build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/metis_cpu.o -L/usr/local/cuda/lib64 -L/home/yons/anaconda3/envs/torch/lib -lcudart -lcudart -lcudart -lcudart -lcudart -lcudart -lcudart -lcudart -lcudart -lpython3.6m -o build/lib.linux-x86_64-3.6/torch_sparse/_metis.so -lcusparse -l cusparse\n",
      "    building 'torch_sparse._sample' extension\n",
      "    gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/tmp/pip-install-_leqep1z/torch-sparse/csrc -I/home/yons/.local/lib/python3.6/site-packages/torch/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/TH -I/home/yons/.local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/yons/anaconda3/envs/torch/include/python3.6m -c /tmp/pip-install-_leqep1z/torch-sparse/csrc/sample.cpp -o build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/sample.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_sample -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "    gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_CUDA -I/tmp/pip-install-_leqep1z/torch-sparse/csrc -I/home/yons/.local/lib/python3.6/site-packages/torch/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/home/yons/.local/lib/python3.6/site-packages/torch/include/TH -I/home/yons/.local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/home/yons/anaconda3/envs/torch/include/python3.6m -c /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp -o build/temp.linux-x86_64-3.6/tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_sample -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp: In function ‘std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> sample_adj_cpu(at::Tensor, at::Tensor, at::Tensor, at::Tensor, int64_t, bool)’:\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:14:45: error: expected primary-expression before ‘>’ token\n",
      "       auto rowptr_data = rowptr.data_ptr<int64_t>();\n",
      "                                                 ^\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:14:47: error: expected primary-expression before ‘)’ token\n",
      "       auto rowptr_data = rowptr.data_ptr<int64_t>();\n",
      "                                                   ^\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:15:39: error: expected primary-expression before ‘>’ token\n",
      "       auto col_data = col.data_ptr<int64_t>();\n",
      "                                           ^\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:15:41: error: expected primary-expression before ‘)’ token\n",
      "       auto col_data = col.data_ptr<int64_t>();\n",
      "                                             ^\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:16:49: error: expected primary-expression before ‘>’ token\n",
      "       auto rowcount_data = rowcount.data_ptr<int64_t>();\n",
      "                                                     ^\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:16:51: error: expected primary-expression before ‘)’ token\n",
      "       auto rowcount_data = rowcount.data_ptr<int64_t>();\n",
      "                                                       ^\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:17:39: error: expected primary-expression before ‘>’ token\n",
      "       auto idx_data = idx.data_ptr<int64_t>();\n",
      "                                           ^\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:17:41: error: expected primary-expression before ‘)’ token\n",
      "       auto idx_data = idx.data_ptr<int64_t>();\n",
      "                                             ^\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:20:53: error: expected primary-expression before ‘>’ token\n",
      "       auto out_rowptr_data = out_rowptr.data_ptr<int64_t>();\n",
      "                                                         ^\n",
      "    /tmp/pip-install-_leqep1z/torch-sparse/csrc/cpu/sample_cpu.cpp:20:55: error: expected primary-expression before ‘)’ token\n",
      "       auto out_rowptr_data = out_rowptr.data_ptr<int64_t>();\n",
      "                                                           ^\n",
      "    error: command 'gcc' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /home/yons/anaconda3/envs/torch/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-_leqep1z/torch-sparse/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-_leqep1z/torch-sparse/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-3p6ks07m/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# !pip install torch_sparse # 安装有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8bbb30086a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#数据集加载\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlanetoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlanetoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./tmp/Cora'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Cora'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_node_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "#数据集加载\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='./tmp/Cora', name='Cora')\n",
    "len(dataset), dataset.num_classes, dataset.num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m./tmp/Cora/\u001b[00m\n",
      "├── \u001b[01;34mprocessed\u001b[00m\n",
      "│   ├── data.pt\n",
      "│   ├── pre_filter.pt\n",
      "│   └── pre_transform.pt\n",
      "└── \u001b[01;34mraw\u001b[00m\n",
      "    ├── ind.cora.allx\n",
      "    ├── ind.cora.ally\n",
      "    ├── ind.cora.graph\n",
      "    ├── ind.cora.test.index\n",
      "    ├── ind.cora.tx\n",
      "    ├── ind.cora.ty\n",
      "    ├── ind.cora.x\n",
      "    └── ind.cora.y\n",
      "\n",
      "2 directories, 11 files\n"
     ]
    }
   ],
   "source": [
    "!tree ./tmp/Cora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GCNConv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bb98a38c8860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bb98a38c8860>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_node_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GCNConv' is not defined"
     ]
    }
   ],
   "source": [
    "#网络定义\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "网络的输入输入是什么？\n",
    "\n",
    "2708篇论文，1403 个单词。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2708, 1433]), torch.Size([2708]), torch.Size([2, 10556]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape, data.y.shape, data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#网络训练\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "需要看看输出是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2\n",
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7970\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 快速 Citeseer\n",
    "\n",
    "\n",
    "Citeseer：一个论文之间引用信息数据集，论文分为6类：Agents、AI、DB、IR、ML和HCI，共包含3312篇论文；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "#数据集加载\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='/tmp/Citeseer', name='Citeseer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mPlanetoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "The citation network datasets \"Cora\", \"CiteSeer\" and \"PubMed\" from the\n",
       "`\"Revisiting Semi-Supervised Learning with Graph Embeddings\"\n",
       "<https://arxiv.org/abs/1603.08861>`_ paper.\n",
       "Nodes represent documents and edges represent citation links.\n",
       "Training, validation and test splits are given by binary masks.\n",
       "\n",
       "Args:\n",
       "    root (string): Root directory where the dataset should be saved.\n",
       "    name (string): The name of the dataset (:obj:`\"Cora\"`,\n",
       "        :obj:`\"CiteSeer\"`, :obj:`\"PubMed\"`).\n",
       "    transform (callable, optional): A function/transform that takes in an\n",
       "        :obj:`torch_geometric.data.Data` object and returns a transformed\n",
       "        version. The data object will be transformed before every access.\n",
       "        (default: :obj:`None`)\n",
       "    pre_transform (callable, optional): A function/transform that takes in\n",
       "        an :obj:`torch_geometric.data.Data` object and returns a\n",
       "        transformed version. The data object will be transformed before\n",
       "        being saved to disk. (default: :obj:`None`)\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/torch_geometric/datasets/planetoid.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6860\n"
     ]
    }
   ],
   "source": [
    "#网络定义\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 32)\n",
    "        self.conv2 = GCNConv(32, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "#网络训练\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#测试\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Graph Attention Network\n",
    "\n",
    "我需要快速实现 Graph Attention Network. 官方教程中有。。。。\n",
    "\n",
    "\n",
    "\n",
    "官方教程中有一个显卡使用的问题 RuntimeError: CUDA error: invalid device function， 我绕过去了。see https://github.com/rusty1s/pytorch_geometric/blob/master/examples/gat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Cora'\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False, False, False])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data  = dataset[0]\n",
    "data.train_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)\n",
    "path = osp.join('./tmp', dataset)\n",
    "dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GATConv(dataset.num_features, 8, heads=8, dropout=0.6)\n",
    "        # On the Pubmed dataset, use heads=8 in conv2.\n",
    "        self.conv2 = GATConv(\n",
    "            8 * 8, dataset.num_classes, heads=1, concat=True, dropout=0.6)\n",
    "\n",
    "    def forward(self):\n",
    "        x = F.dropout(data.x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, data.edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, data.edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 4, 4,  ..., 3, 3, 3]), None, True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y, device.index, torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train: 0.5000, Val: 0.4140, Test: 0.4090\n",
      "Epoch: 002, Train: 0.6643, Val: 0.5360, Test: 0.5070\n",
      "Epoch: 003, Train: 0.7357, Val: 0.5860, Test: 0.5540\n",
      "Epoch: 004, Train: 0.7857, Val: 0.6020, Test: 0.5860\n",
      "Epoch: 005, Train: 0.8429, Val: 0.6440, Test: 0.6470\n",
      "Epoch: 006, Train: 0.8857, Val: 0.6740, Test: 0.6850\n",
      "Epoch: 007, Train: 0.9071, Val: 0.6960, Test: 0.7120\n",
      "Epoch: 008, Train: 0.9143, Val: 0.7140, Test: 0.7320\n",
      "Epoch: 009, Train: 0.9286, Val: 0.7300, Test: 0.7490\n",
      "Epoch: 010, Train: 0.9357, Val: 0.7400, Test: 0.7560\n",
      "Epoch: 011, Train: 0.9429, Val: 0.7520, Test: 0.7660\n",
      "Epoch: 012, Train: 0.9500, Val: 0.7500, Test: 0.7660\n",
      "Epoch: 013, Train: 0.9500, Val: 0.7500, Test: 0.7700\n",
      "Epoch: 014, Train: 0.9500, Val: 0.7520, Test: 0.7660\n",
      "Epoch: 015, Train: 0.9500, Val: 0.7520, Test: 0.7640\n",
      "Epoch: 016, Train: 0.9500, Val: 0.7540, Test: 0.7630\n",
      "Epoch: 017, Train: 0.9500, Val: 0.7520, Test: 0.7650\n",
      "Epoch: 018, Train: 0.9500, Val: 0.7480, Test: 0.7690\n",
      "Epoch: 019, Train: 0.9571, Val: 0.7520, Test: 0.7670\n",
      "Epoch: 020, Train: 0.9643, Val: 0.7500, Test: 0.7640\n",
      "Epoch: 021, Train: 0.9714, Val: 0.7440, Test: 0.7640\n",
      "Epoch: 022, Train: 0.9714, Val: 0.7460, Test: 0.7640\n",
      "Epoch: 023, Train: 0.9714, Val: 0.7460, Test: 0.7630\n",
      "Epoch: 024, Train: 0.9714, Val: 0.7460, Test: 0.7610\n",
      "Epoch: 025, Train: 0.9714, Val: 0.7480, Test: 0.7610\n",
      "Epoch: 026, Train: 0.9714, Val: 0.7480, Test: 0.7630\n",
      "Epoch: 027, Train: 0.9643, Val: 0.7460, Test: 0.7630\n",
      "Epoch: 028, Train: 0.9643, Val: 0.7460, Test: 0.7630\n",
      "Epoch: 029, Train: 0.9643, Val: 0.7480, Test: 0.7660\n",
      "Epoch: 030, Train: 0.9643, Val: 0.7480, Test: 0.7710\n",
      "Epoch: 031, Train: 0.9643, Val: 0.7520, Test: 0.7700\n",
      "Epoch: 032, Train: 0.9714, Val: 0.7520, Test: 0.7710\n",
      "Epoch: 033, Train: 0.9786, Val: 0.7560, Test: 0.7750\n",
      "Epoch: 034, Train: 0.9857, Val: 0.7580, Test: 0.7760\n",
      "Epoch: 035, Train: 0.9857, Val: 0.7600, Test: 0.7740\n",
      "Epoch: 036, Train: 0.9857, Val: 0.7620, Test: 0.7730\n",
      "Epoch: 037, Train: 0.9786, Val: 0.7640, Test: 0.7740\n",
      "Epoch: 038, Train: 0.9786, Val: 0.7640, Test: 0.7740\n",
      "Epoch: 039, Train: 0.9786, Val: 0.7600, Test: 0.7720\n",
      "Epoch: 040, Train: 0.9786, Val: 0.7620, Test: 0.7730\n",
      "Epoch: 041, Train: 0.9857, Val: 0.7620, Test: 0.7730\n",
      "Epoch: 042, Train: 0.9857, Val: 0.7660, Test: 0.7740\n",
      "Epoch: 043, Train: 0.9857, Val: 0.7660, Test: 0.7750\n",
      "Epoch: 044, Train: 0.9857, Val: 0.7660, Test: 0.7750\n",
      "Epoch: 045, Train: 0.9857, Val: 0.7640, Test: 0.7760\n",
      "Epoch: 046, Train: 0.9857, Val: 0.7640, Test: 0.7750\n",
      "Epoch: 047, Train: 0.9929, Val: 0.7620, Test: 0.7750\n",
      "Epoch: 048, Train: 0.9929, Val: 0.7580, Test: 0.7770\n",
      "Epoch: 049, Train: 0.9929, Val: 0.7580, Test: 0.7780\n",
      "Epoch: 050, Train: 0.9929, Val: 0.7560, Test: 0.7810\n",
      "Epoch: 051, Train: 0.9929, Val: 0.7560, Test: 0.7830\n",
      "Epoch: 052, Train: 0.9929, Val: 0.7580, Test: 0.7840\n",
      "Epoch: 053, Train: 0.9929, Val: 0.7580, Test: 0.7840\n",
      "Epoch: 054, Train: 0.9929, Val: 0.7560, Test: 0.7830\n",
      "Epoch: 055, Train: 1.0000, Val: 0.7560, Test: 0.7830\n",
      "Epoch: 056, Train: 1.0000, Val: 0.7540, Test: 0.7840\n",
      "Epoch: 057, Train: 1.0000, Val: 0.7540, Test: 0.7850\n",
      "Epoch: 058, Train: 1.0000, Val: 0.7560, Test: 0.7850\n",
      "Epoch: 059, Train: 1.0000, Val: 0.7560, Test: 0.7860\n",
      "Epoch: 060, Train: 1.0000, Val: 0.7580, Test: 0.7900\n",
      "Epoch: 061, Train: 1.0000, Val: 0.7580, Test: 0.7910\n",
      "Epoch: 062, Train: 1.0000, Val: 0.7600, Test: 0.7920\n",
      "Epoch: 063, Train: 1.0000, Val: 0.7620, Test: 0.7910\n",
      "Epoch: 064, Train: 1.0000, Val: 0.7620, Test: 0.7900\n",
      "Epoch: 065, Train: 1.0000, Val: 0.7600, Test: 0.7880\n",
      "Epoch: 066, Train: 1.0000, Val: 0.7640, Test: 0.7870\n",
      "Epoch: 067, Train: 1.0000, Val: 0.7620, Test: 0.7870\n",
      "Epoch: 068, Train: 1.0000, Val: 0.7680, Test: 0.7890\n",
      "Epoch: 069, Train: 1.0000, Val: 0.7680, Test: 0.7910\n",
      "Epoch: 070, Train: 1.0000, Val: 0.7680, Test: 0.7920\n",
      "Epoch: 071, Train: 1.0000, Val: 0.7680, Test: 0.7920\n",
      "Epoch: 072, Train: 1.0000, Val: 0.7680, Test: 0.7950\n",
      "Epoch: 073, Train: 1.0000, Val: 0.7700, Test: 0.7970\n",
      "Epoch: 074, Train: 1.0000, Val: 0.7700, Test: 0.7970\n",
      "Epoch: 075, Train: 1.0000, Val: 0.7680, Test: 0.7970\n",
      "Epoch: 076, Train: 1.0000, Val: 0.7700, Test: 0.7970\n",
      "Epoch: 077, Train: 1.0000, Val: 0.7660, Test: 0.7950\n",
      "Epoch: 078, Train: 1.0000, Val: 0.7660, Test: 0.7960\n",
      "Epoch: 079, Train: 1.0000, Val: 0.7700, Test: 0.7970\n",
      "Epoch: 080, Train: 1.0000, Val: 0.7640, Test: 0.7980\n",
      "Epoch: 081, Train: 1.0000, Val: 0.7640, Test: 0.8000\n",
      "Epoch: 082, Train: 1.0000, Val: 0.7660, Test: 0.8000\n",
      "Epoch: 083, Train: 1.0000, Val: 0.7640, Test: 0.8000\n",
      "Epoch: 084, Train: 1.0000, Val: 0.7640, Test: 0.8000\n",
      "Epoch: 085, Train: 1.0000, Val: 0.7660, Test: 0.8000\n",
      "Epoch: 086, Train: 1.0000, Val: 0.7660, Test: 0.7980\n",
      "Epoch: 087, Train: 1.0000, Val: 0.7660, Test: 0.7960\n",
      "Epoch: 088, Train: 1.0000, Val: 0.7660, Test: 0.7960\n",
      "Epoch: 089, Train: 1.0000, Val: 0.7660, Test: 0.7980\n",
      "Epoch: 090, Train: 1.0000, Val: 0.7660, Test: 0.7960\n",
      "Epoch: 091, Train: 1.0000, Val: 0.7620, Test: 0.7960\n",
      "Epoch: 092, Train: 1.0000, Val: 0.7600, Test: 0.7970\n",
      "Epoch: 093, Train: 1.0000, Val: 0.7620, Test: 0.7980\n",
      "Epoch: 094, Train: 1.0000, Val: 0.7640, Test: 0.7970\n",
      "Epoch: 095, Train: 1.0000, Val: 0.7660, Test: 0.7980\n",
      "Epoch: 096, Train: 1.0000, Val: 0.7660, Test: 0.7970\n",
      "Epoch: 097, Train: 1.0000, Val: 0.7660, Test: 0.7960\n",
      "Epoch: 098, Train: 1.0000, Val: 0.7680, Test: 0.7960\n",
      "Epoch: 099, Train: 1.0000, Val: 0.7680, Test: 0.7960\n",
      "Epoch: 100, Train: 1.0000, Val: 0.7720, Test: 0.7980\n",
      "Epoch: 101, Train: 1.0000, Val: 0.7720, Test: 0.7960\n",
      "Epoch: 102, Train: 1.0000, Val: 0.7720, Test: 0.7980\n",
      "Epoch: 103, Train: 1.0000, Val: 0.7740, Test: 0.8010\n",
      "Epoch: 104, Train: 1.0000, Val: 0.7720, Test: 0.8010\n",
      "Epoch: 105, Train: 1.0000, Val: 0.7740, Test: 0.8010\n",
      "Epoch: 106, Train: 1.0000, Val: 0.7740, Test: 0.8010\n",
      "Epoch: 107, Train: 1.0000, Val: 0.7740, Test: 0.8010\n",
      "Epoch: 108, Train: 1.0000, Val: 0.7720, Test: 0.8020\n",
      "Epoch: 109, Train: 1.0000, Val: 0.7720, Test: 0.8010\n",
      "Epoch: 110, Train: 1.0000, Val: 0.7700, Test: 0.8020\n",
      "Epoch: 111, Train: 1.0000, Val: 0.7700, Test: 0.8010\n",
      "Epoch: 112, Train: 1.0000, Val: 0.7720, Test: 0.7990\n",
      "Epoch: 113, Train: 1.0000, Val: 0.7720, Test: 0.8000\n",
      "Epoch: 114, Train: 1.0000, Val: 0.7700, Test: 0.7970\n",
      "Epoch: 115, Train: 1.0000, Val: 0.7760, Test: 0.7950\n",
      "Epoch: 116, Train: 1.0000, Val: 0.7740, Test: 0.7930\n",
      "Epoch: 117, Train: 1.0000, Val: 0.7720, Test: 0.7930\n",
      "Epoch: 118, Train: 1.0000, Val: 0.7680, Test: 0.7930\n",
      "Epoch: 119, Train: 1.0000, Val: 0.7680, Test: 0.7930\n",
      "Epoch: 120, Train: 1.0000, Val: 0.7680, Test: 0.7920\n",
      "Epoch: 121, Train: 1.0000, Val: 0.7660, Test: 0.7890\n",
      "Epoch: 122, Train: 1.0000, Val: 0.7660, Test: 0.7890\n",
      "Epoch: 123, Train: 1.0000, Val: 0.7680, Test: 0.7910\n",
      "Epoch: 124, Train: 1.0000, Val: 0.7680, Test: 0.7910\n",
      "Epoch: 125, Train: 1.0000, Val: 0.7700, Test: 0.7920\n",
      "Epoch: 126, Train: 1.0000, Val: 0.7680, Test: 0.7920\n",
      "Epoch: 127, Train: 1.0000, Val: 0.7700, Test: 0.7930\n",
      "Epoch: 128, Train: 1.0000, Val: 0.7720, Test: 0.7930\n",
      "Epoch: 129, Train: 1.0000, Val: 0.7740, Test: 0.7930\n",
      "Epoch: 130, Train: 1.0000, Val: 0.7720, Test: 0.7920\n",
      "Epoch: 131, Train: 1.0000, Val: 0.7720, Test: 0.7940\n",
      "Epoch: 132, Train: 1.0000, Val: 0.7720, Test: 0.7960\n",
      "Epoch: 133, Train: 1.0000, Val: 0.7720, Test: 0.7970\n",
      "Epoch: 134, Train: 1.0000, Val: 0.7660, Test: 0.7950\n",
      "Epoch: 135, Train: 1.0000, Val: 0.7680, Test: 0.7930\n",
      "Epoch: 136, Train: 1.0000, Val: 0.7700, Test: 0.7950\n",
      "Epoch: 137, Train: 1.0000, Val: 0.7700, Test: 0.7950\n",
      "Epoch: 138, Train: 1.0000, Val: 0.7680, Test: 0.7940\n",
      "Epoch: 139, Train: 1.0000, Val: 0.7700, Test: 0.7950\n",
      "Epoch: 140, Train: 1.0000, Val: 0.7660, Test: 0.7950\n",
      "Epoch: 141, Train: 1.0000, Val: 0.7640, Test: 0.7960\n",
      "Epoch: 142, Train: 1.0000, Val: 0.7660, Test: 0.7980\n",
      "Epoch: 143, Train: 1.0000, Val: 0.7680, Test: 0.7970\n",
      "Epoch: 144, Train: 1.0000, Val: 0.7720, Test: 0.7970\n",
      "Epoch: 145, Train: 1.0000, Val: 0.7740, Test: 0.7970\n",
      "Epoch: 146, Train: 1.0000, Val: 0.7740, Test: 0.7970\n",
      "Epoch: 147, Train: 1.0000, Val: 0.7760, Test: 0.7990\n",
      "Epoch: 148, Train: 1.0000, Val: 0.7740, Test: 0.7980\n",
      "Epoch: 149, Train: 1.0000, Val: 0.7740, Test: 0.7980\n",
      "Epoch: 150, Train: 1.0000, Val: 0.7720, Test: 0.7980\n",
      "Epoch: 151, Train: 1.0000, Val: 0.7720, Test: 0.7990\n",
      "Epoch: 152, Train: 1.0000, Val: 0.7720, Test: 0.7980\n",
      "Epoch: 153, Train: 1.0000, Val: 0.7720, Test: 0.7990\n",
      "Epoch: 154, Train: 1.0000, Val: 0.7700, Test: 0.8000\n",
      "Epoch: 155, Train: 1.0000, Val: 0.7700, Test: 0.7980\n",
      "Epoch: 156, Train: 1.0000, Val: 0.7720, Test: 0.7980\n",
      "Epoch: 157, Train: 1.0000, Val: 0.7740, Test: 0.7990\n",
      "Epoch: 158, Train: 1.0000, Val: 0.7740, Test: 0.8010\n",
      "Epoch: 159, Train: 1.0000, Val: 0.7700, Test: 0.8010\n",
      "Epoch: 160, Train: 1.0000, Val: 0.7660, Test: 0.7990\n",
      "Epoch: 161, Train: 1.0000, Val: 0.7680, Test: 0.7970\n",
      "Epoch: 162, Train: 1.0000, Val: 0.7720, Test: 0.7960\n",
      "Epoch: 163, Train: 1.0000, Val: 0.7680, Test: 0.7960\n",
      "Epoch: 164, Train: 1.0000, Val: 0.7680, Test: 0.7960\n",
      "Epoch: 165, Train: 1.0000, Val: 0.7660, Test: 0.7980\n",
      "Epoch: 166, Train: 1.0000, Val: 0.7660, Test: 0.7940\n",
      "Epoch: 167, Train: 1.0000, Val: 0.7680, Test: 0.7950\n",
      "Epoch: 168, Train: 1.0000, Val: 0.7660, Test: 0.7960\n",
      "Epoch: 169, Train: 1.0000, Val: 0.7680, Test: 0.7970\n",
      "Epoch: 170, Train: 1.0000, Val: 0.7680, Test: 0.7960\n",
      "Epoch: 171, Train: 1.0000, Val: 0.7680, Test: 0.7930\n",
      "Epoch: 172, Train: 1.0000, Val: 0.7680, Test: 0.7940\n",
      "Epoch: 173, Train: 1.0000, Val: 0.7680, Test: 0.7940\n",
      "Epoch: 174, Train: 1.0000, Val: 0.7720, Test: 0.7940\n",
      "Epoch: 175, Train: 1.0000, Val: 0.7720, Test: 0.7930\n",
      "Epoch: 176, Train: 1.0000, Val: 0.7720, Test: 0.7920\n",
      "Epoch: 177, Train: 1.0000, Val: 0.7720, Test: 0.7910\n",
      "Epoch: 178, Train: 1.0000, Val: 0.7700, Test: 0.7940\n",
      "Epoch: 179, Train: 1.0000, Val: 0.7700, Test: 0.7930\n",
      "Epoch: 180, Train: 1.0000, Val: 0.7720, Test: 0.7920\n",
      "Epoch: 181, Train: 1.0000, Val: 0.7700, Test: 0.7890\n",
      "Epoch: 182, Train: 1.0000, Val: 0.7700, Test: 0.7890\n",
      "Epoch: 183, Train: 1.0000, Val: 0.7700, Test: 0.7890\n",
      "Epoch: 184, Train: 1.0000, Val: 0.7700, Test: 0.7900\n",
      "Epoch: 185, Train: 1.0000, Val: 0.7700, Test: 0.7890\n",
      "Epoch: 186, Train: 1.0000, Val: 0.7700, Test: 0.7910\n",
      "Epoch: 187, Train: 1.0000, Val: 0.7700, Test: 0.7900\n",
      "Epoch: 188, Train: 1.0000, Val: 0.7760, Test: 0.7920\n",
      "Epoch: 189, Train: 1.0000, Val: 0.7760, Test: 0.7920\n",
      "Epoch: 190, Train: 1.0000, Val: 0.7760, Test: 0.7920\n",
      "Epoch: 191, Train: 1.0000, Val: 0.7740, Test: 0.7920\n",
      "Epoch: 192, Train: 1.0000, Val: 0.7760, Test: 0.7940\n",
      "Epoch: 193, Train: 1.0000, Val: 0.7740, Test: 0.7970\n",
      "Epoch: 194, Train: 1.0000, Val: 0.7740, Test: 0.7970\n",
      "Epoch: 195, Train: 1.0000, Val: 0.7680, Test: 0.7990\n",
      "Epoch: 196, Train: 1.0000, Val: 0.7700, Test: 0.8000\n",
      "Epoch: 197, Train: 1.0000, Val: 0.7720, Test: 0.7970\n",
      "Epoch: 198, Train: 1.0000, Val: 0.7720, Test: 0.7990\n",
      "Epoch: 199, Train: 1.0000, Val: 0.7740, Test: 0.8000\n",
      "Epoch: 200, Train: 1.0000, Val: 0.7740, Test: 0.7980\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    print(log.format(epoch, *test()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 通俗理解\n",
    "\n",
    "需要一些关于图网络的通俗理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- PyTorch Geometric 攻略\n",
    "\n",
    "在 PyTorch Geometric 中，一个图被定义为g=(X,(I,E))，其中X表示节点的特征矩阵，N为节点的个数，F为每个节点的特征数；用I,E这种元组形式表示图的稀疏邻接矩阵，I为边的索引，E为D维的边特征。用于模型的图（graph）数据包括对象（nodes）及成对对象之间的关系（edges）组成。用于 PyTorch Geometric 中的每个图都是一个 torch_geometric.data.Data 类型的实例，其属性有：\n",
    "\n",
    "- data.x：节点特征矩阵，形状为 [num_nodes, num_node_features]。\n",
    "- data.edge_index：COO 格式的图的边关系，形状为 [2, num_edges]，类型为 torch.long\n",
    "- data.edge_attr：边特征矩阵，形状为[num_edges, num_edge_features]\n",
    "- data.y：针对训练的目标可能具有不同的形状\n",
    "- data.pos：节点的位置矩阵，形状为[num_nodes, num_dimensions]\n",
    "\n",
    "Data 对象不是必须有上面所有的这些属性，也不是只能有这些属性。比如，我们可以通过data.face进行扩展，用一个张量（tensor）来保存一个3D网格的三元链接关系，形状为 [3, num_faces]，类型为 torch.long。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- 官方理解 [Creating Message Passing Networks](https://github.com/rusty1s/pytorch_geometric/blob/master/docs/source/notes/create_gnn.rst)\n",
    "\n",
    "\n",
    "Generalizing the convolution operator to irregular domains is typically expressed as a *neighborhood aggregation* or *message passing* scheme. With $\\mathbf{x}^{(k-1)}_i \\in \\mathbb{R}^F$ denoting node features of node $i$ in layer $(k-1)$ and $\\mathbf{e}_{i,j} \\in \\mathbb{R}^D$ denoting (optional) edge features from node $i$ to node $j$, message passing graph neural networks can be described as\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{i,j}\\right) \\right),\n",
    "$$\n",
    "\n",
    "where $\\square$ denotes a differentiable, permutation invariant function, e.g., sum, mean or max, and $\\gamma$ and $\\phi$ denote differentiable functions such as MLPs (Multi Layer Perceptrons)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# End to End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Zero to All\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 重要资料\n",
    "\n",
    "- GCN作者 slide http://tkipf.github.io/misc/SlidesCambridge.pdf\n",
    "\n",
    "- 清华 Peng Cui http://www.cips-cl.org/static/CCL2019/downloads/tutorialsPPT/02.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- https://github.com/rusty1s/pytorch_geometric\n",
    "\n",
    "PyTorch Geometric (PyG) is a geometric deep learning extension library for PyTorch.\n",
    "\n",
    "It consists of various methods for deep learning on graphs and other irregular structures, also known as geometric deep learning, from a variety of published papers. In addition, it consists of an easy-to-use mini-batch loader for many small and single giant graphs, multi gpu-support, a large number of common benchmark datasets (based on simple interfaces to create your own), and helpful transforms, both for learning on arbitrary graphs as well as on 3D meshes or point clouds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- https://pytorch-geometric.readthedocs.io/en/latest/index.html\n",
    "\n",
    "PyTorch Geometric user document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## 图卷积层\n",
    "\n",
    "我们需要指导图卷积层的数学原理和实现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: 增加自连接到邻接矩阵\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: 对节点的特征矩阵进行线性变换\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, x_j, edge_index, size):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 3: Normalize node features.\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "        # Step 5: Return new node embeddings.\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
